
## Arquivos de configuração .CFG
Os arquivos de extensão .cfg são arquivos que possuem configurações para a execução do algoritmo de reinforcement learning. Esses arquivos são uma alternativa que facilita a execução e o debug dos treinamentos/testes dos agentes nos ambientes escolhidos. Ao invés de digitar longos códigos no terminal para a execução do script, escrevemos essa configuração em arquivo .cfg de mesmo nome do script a ser executado, como, por exemplo, Base_agent.cfg para o script Base_agent.py. Debaixo dos panos, o que o script faz é ler o arquivo .cfg e transformar as linhas válidas de código dentro do mesmo em comandos de terminais que, convertidos, são enviados ao Argparser antes da inicialização. Assim, uma linha de código env = Doom se transforma em --env Doom e é enviada ao método main do arquivo executado.
Um cuidado necessário na execução de nosso script configurado em um arquivo .cfg é que :**Caso algum comando de terminal seja enviado, a configuração de execução do script será feita exclusivamente pelo terminal, e os parâmetros não enviados terão seus valores atribuídos como default.** Se nenhum parâmetro for enviado via terminal, o script procurará por um arquivo de mesmo nome com extensão .cfg. Dentro deste arquivo, caso encontre configurações válidas, estas serão lidas de forma similar à configuração via terminal e os valores não definidos serão atribuídos aos seus valores default.

### Escrevendo os arquivos .cfg
As regras de escrita dos arquivos .cfg são as seguintes:
- Linhas começando com os caracteres **#** ou **;** são tratadas como comentários.
- Linhas começando com o caractere **+** são continuações de linhas anteriores. Por exemplo, um path do sistema que é muito longo.
- As linhas não são Case sensitive, ou seja, não há distinção entre minúscula ou maiúscula (ENV = DOOM é igual a env = Doom).
- Cada linha **deve possuir apenas um par de chave = valor**. Por exemplo, agent_mode = train em uma linha e na próxima env = doom, assim sucessivamente.
- Se um argumento não estiver especificado no arquivo .cfg e seja necessário para execução da tarefa desejada, seu valor padrão será carregado. Isto foi feito para evitar a necessidade de constantemente ter que escrever parâmetros que tenham seus valores frequentes entre simulações. Para ver quais são os valores padrões de cada variável verificar o [DOC](https://github.com/Leonardo-Viana/Reinforcement-Learning/blob/master/docs/ptbr/doc_ptbr.md) e para exemplos e cuidados sobre esses valores verificar a sessão de [Exemplos](https://github.com/Leonardo-Viana/Reinforcement-Learning/blob/master/docs/ptbr/examples_ptbr.md).
- Caminhos relativos ao diretório principal podem ser inseridos utilizando os dois pontos (..) antes do path. Por exemplo: para acessar o diretório Weights, ao invés de especificarmos todo o path do sistema, podemos inserir apenas: ../Weights
- Os comandos serão lidos em sequência, logo, em caso de comandos repetidos, apenas o último será válido.
